{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIZTAB8piXP7"
      },
      "source": [
        "# Práctica 6: MODELADO DE PROTEÍNAS PARA EL DISEÑO RACIONAL DE FÁRMACOS\n",
        "## 1. Introducción\n",
        "\n",
        "Las estructuras de las proteínas determinan con qué moléculas va a interaccionar y, por tanto, su función. Actualmente, los métodos de determinación de secuencias de proteínas están muy optimizados, pero no los de [estructuras tridimensionales](https://pdb101.rcsb.org/learn/guide-to-understanding-pdb-data/methods-for-determining-structure). Actualmente las técnicas que proporcionan información de las estructuras de macromoléculas biológicas son:\n",
        "\n",
        "* [Resonancia Magnética Nuclear (RMN)](https://www.youtube.com/watch?v=t8JIBwLsCGA)\n",
        "* [Crio-Microscopia Electrónica](https://www.youtube.com/watch?v=vLo7oqfRa74)\n",
        "* [Cristalografía de rayos X](https://www.youtube.com/watch?v=RUok4O9oovQ) (esta técnica la veremos en más detalle en la asignatura de Técnicas Instrumentales Avanzadas)\n",
        "\n",
        "Podemos obtener la estructura final de la macromolécula por medio de estas estas técnicas, pero es un proceso muy laboriosas y con un alto coste económico.\n",
        "\n",
        "En los años 1960, los experimentos pioneros de [Anfinsen](https://www.bbvaopenmind.com/ciencia/biociencias/anfinsen-y-la-arquitectura-de-las-proteinas/) con la ribinucleasa fueron claves para demostrar algo que actualmente esta totalmente admitido: el plegamiento tridimensional final de la proteína esta dictado por su secuencia de aminoácidos. Estos experimentos se realizaron con la proteína **ribonucleasa**, a la que sometió a desnaturalización, es decir a la perdida de sus estructura tridimensional, tratándola con urea.  Cuando se eliminaba la urea, se lograba  de nuevo la estructura tridimensional de la proteína. Al ser esta una enzima se podía comprobar fácilmente  que se obtenía la proteína original mediante ensayos de actividad.  \n",
        "\n",
        "Durante más de 50 años, los científicos han diseñado diferentes protocolos para poder calcular la estructura tridimensional de las proteínas a partir de la secuencia. Una de las iniciativas más importantes es Critical Assessment of protein Structure Prediction [(CASP)](https://predictioncenter.org/casp14/index.cgi).\n",
        "\n",
        "# CASP14 y Alpha Fold 2\n",
        "CASP14 marcó un aumento extraordinario en la precisión de los cálculos de estructuras tridimensionales de proteínas y a ello contribuyo la aparición del método avanzado de [Deep Learning](https://www.xataka.com/robotica-e-ia/deep-learning-que-es-y-por-que-va-a-ser-una-tecnologia-clave-en-el-futuro-de-la-inteligencia-artificial) **AlphaFold2**. Los modelos construidos con este método demostraron alcanzar prácticamente la precisión experimental (GDT_TS>90) para ~2/3 de los objetivos y de alta precisión (GDT_TS>80) para casi el 90% de los objetivos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "## 2. ColabFold v1.5.2: AlphaFold2 utilizando MMseqs2\n",
        "En esta práctica vamos a utilizar el cuaderno desarrollado por Mirdita, Schütze, Moriwaki, Heo, Ovchinnikov y Steinegger\n",
        "y cuyos detalles podéis encontrar en la publicación [\"*ColabFold - Making protein folding accessible to all*\"](https://www.nature.com/articles/s41592-022-01488-1). De esta forma estos autores han facilitado utilizar herramientas complejas de predicción de estructuras cómo [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) y [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). En este cuaderno en concreto las alineaciones/plantillas de secuencia se generan a través de [MMseqs2](https://github.com/soedinglab/mmseqs2) y [HHsearch](https://github.com/soedinglab/hh-suite).\n",
        "\n",
        "#### **Hemos traducido el cuaderno al español para facilitar su uso a los estudiantes del grado de Bioténología de la UAL.**\n",
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "Para más detalles sobre este cuaderno, consultar ColabFold GitHub y leer el manuscrito\n",
        "\n",
        "[Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kOblAo-xetgx"
      },
      "outputs": [],
      "source": [
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "query_sequence = '' #@param {type:\"string\"}\n",
        "#@markdown  - Use `:` to specify inter-protein chainbreaks for **modeling complexes** (supports homo- and hetro-oligomers). For example **PI...SK:PI...SK** for a homodimer\n",
        "jobname = 'test' #@param {type:\"string\"}\n",
        "# number of models to use\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "#@markdown - specify how many of the top ranked structures to relax using amber\n",
        "template_mode = \"none\" #@param [\"none\", \"pdb70\",\"custom\"]\n",
        "#@markdown - `none` = no template information is used. `pdb70` = detect templates in pdb70. `custom` - upload and search own templates (PDB or mmCIF format, see [notes below](#custom_templates))\n",
        "\n",
        "use_amber = num_relax > 0\n",
        "\n",
        "# remove whitespaces\n",
        "query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "basejobname = \"\".join(jobname.split())\n",
        "basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "# check if directory with jobname exists\n",
        "def check(folder):\n",
        "  if os.path.exists(folder):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "if not check(jobname):\n",
        "  n = 0\n",
        "  while not check(f\"{jobname}_{n}\"): n += 1\n",
        "  jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "# make directory to save results\n",
        "os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "# save queries\n",
        "queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "with open(queries_path, \"w\") as text_file:\n",
        "  text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "if template_mode == \"pdb70\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "elif template_mode == \"custom\":\n",
        "  custom_template_path = os.path.join(jobname,f\"template\")\n",
        "  os.makedirs(custom_template_path, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n",
        "\n",
        "print(\"jobname\",jobname)\n",
        "print(\"sequence\",query_sequence)\n",
        "print(\"length\",len(query_sequence.replace(\":\",\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iccGdbe_Pmt9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  echo \"installing colabfold...\"\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\" \"tensorflow-cpu==2.11.0\"\n",
        "  pip uninstall -yq jax jaxlib\n",
        "  pip install -q \"jax[cuda]==0.3.25\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "\n",
        "  # for debugging\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    echo \"installing conda...\"\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    conda config --set auto_update_conda false\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  echo \"installing hhsuite...\"\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  echo \"installing amber...\"\n",
        "  conda install -y -q -c conda-forge openmm=7.5.1 python=\"${PYTHON_VERSION}\" pdbfixer cryptography==38.0.4 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C2_sh2uAonJH"
      },
      "outputs": [],
      "source": [
        "#@markdown ### MSA options (custom MSA upload, single sequence, pairing mode)\n",
        "msa_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
        "pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n",
        "#@markdown - \"unpaired_paired\" = pair sequences from same species + unpaired MSA, \"unpaired\" = seperate MSA for each chain, \"paired\" - only use paired sequences.\n",
        "\n",
        "# decide which a3m to use\n",
        "if \"mmseqs2\" in msa_mode:\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
        "\n",
        "elif msa_mode == \"custom\":\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
        "  if not os.path.isfile(a3m_file):\n",
        "    custom_msa_dict = files.upload()\n",
        "    custom_msa = list(custom_msa_dict.keys())[0]\n",
        "    header = 0\n",
        "    import fileinput\n",
        "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "      if line.startswith(\">\"):\n",
        "         header = header + 1\n",
        "      if not line.rstrip():\n",
        "        continue\n",
        "      if line.startswith(\">\") == False and header == 1:\n",
        "         query_sequence = line.rstrip()\n",
        "      print(line, end='')\n",
        "\n",
        "    os.rename(custom_msa, a3m_file)\n",
        "    queries_path=a3m_file\n",
        "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "\n",
        "else:\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
        "  with open(a3m_file, \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ADDuaolKmjGW"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Advanced settings\n",
        "model_type = \"auto\" #@param [\"auto\", \"alphafold2_ptm\", \"alphafold2_multimer_v1\", \"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\"]\n",
        "#@markdown - if `auto` selected, will use `alphafold2_ptm` for monomer prediction and `alphafold2_multimer_v3` for complex prediction.\n",
        "#@markdown Any of the mode_types can be used (regardless if input is monomer or complex).\n",
        "num_recycles = \"auto\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
        "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
        "#@markdown - if `auto` selected, will use 20 recycles if `model_type=alphafold2_multimer_v3` (with tol=0.5), all else 3 recycles (with tol=0.0).\n",
        "\n",
        "#@markdown #### Sample settings\n",
        "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
        "#@markdown -  decrease `max_msa` to increase uncertainity\n",
        "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
        "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "#@markdown #### Save settings\n",
        "save_all = False #@param {type:\"boolean\"}\n",
        "save_recycles = False #@param {type:\"boolean\"}\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
        "dpi = 200 #@param {type:\"integer\"}\n",
        "#@markdown - set dpi for image resolution\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mbaIO9pWjaN0"
      },
      "outputs": [],
      "source": [
        "#@title Run Prediction\n",
        "display_images = True #@param {type:\"boolean\"}\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from Bio import BiopythonDeprecationWarning\n",
        "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "from pathlib import Path\n",
        "from colabfold.download import download_alphafold_params, default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from colabfold.batch import get_queries, run, set_model_type\n",
        "from colabfold.plot import plot_msa_v2\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "try:\n",
        "  K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "except:\n",
        "  K80_chk = \"0\"\n",
        "  pass\n",
        "if \"1\" in K80_chk:\n",
        "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "from colabfold.colabfold import plot_protein\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "def input_features_callback(input_features):\n",
        "  if display_images:\n",
        "    plot_msa_v2(input_features)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def prediction_callback(protein_obj, length,\n",
        "                        prediction_result, input_features, mode):\n",
        "  model_name, relaxed = mode\n",
        "  if not relaxed:\n",
        "    if display_images:\n",
        "      fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
        "      plt.show()\n",
        "      plt.close()\n",
        "\n",
        "result_dir = jobname\n",
        "if 'logging_setup' not in globals():\n",
        "    setup_logging(Path(os.path.join(jobname,\"log.txt\")))\n",
        "    logging_setup = True\n",
        "\n",
        "queries, is_complex = get_queries(queries_path)\n",
        "model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "if \"multimer\" in model_type and max_msa is not None:\n",
        "  use_cluster_profile = False\n",
        "else:\n",
        "  use_cluster_profile = True\n",
        "\n",
        "download_alphafold_params(model_type, Path(\".\"))\n",
        "results = run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    custom_template_path=custom_template_path,\n",
        "    num_relax=num_relax,\n",
        "    msa_mode=msa_mode,\n",
        "    model_type=model_type,\n",
        "    num_models=5,\n",
        "    num_recycles=num_recycles,\n",
        "    recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "    num_seeds=num_seeds,\n",
        "    use_dropout=use_dropout,\n",
        "    model_order=[1,2,3,4,5],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=Path(\".\"),\n",
        "    keep_existing_results=False,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=pair_mode,\n",
        "    stop_at_score=float(100),\n",
        "    prediction_callback=prediction_callback,\n",
        "    dpi=dpi,\n",
        "    zip_results=False,\n",
        "    save_all=save_all,\n",
        "    max_msa=max_msa,\n",
        "    use_cluster_profile=use_cluster_profile,\n",
        "    input_features_callback=input_features_callback,\n",
        "    save_recycles=save_recycles,\n",
        ")\n",
        "results_zip = f\"{jobname}.result.zip\"\n",
        "os.system(f\"zip -r {results_zip} {jobname}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KK7X9T44pWb7"
      },
      "outputs": [],
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "import py3Dmol\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from colabfold.colabfold import plot_plddt_legend\n",
        "from colabfold.colabfold import pymol_color_list, alphabet_list\n",
        "rank_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "\n",
        "tag = results[\"rank\"][0][rank_num - 1]\n",
        "jobname_prefix = \".custom\" if msa_mode == \"custom\" else \"\"\n",
        "pdb_filename = f\"{jobname}/{jobname}{jobname_prefix}_unrelaxed_{tag}.pdb\"\n",
        "pdb_file = glob.glob(pdb_filename)\n",
        "\n",
        "def show_pdb(rank_num=1, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
        "  model_name = f\"rank_{rank_num}\"\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "  view.addModel(open(pdb_file[0],'r').read(),'pdb')\n",
        "\n",
        "  if color == \"lDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    chains = len(queries[0][1]) + 1 if is_complex else 1\n",
        "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "\n",
        "  view.zoomTo()\n",
        "  return view\n",
        "\n",
        "show_pdb(rank_num, show_sidechains, show_mainchains, color).show()\n",
        "if color == \"lDDT\":\n",
        "  plot_plddt_legend().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "11l8k--10q0C"
      },
      "outputs": [],
      "source": [
        "#@title Plots {run: \"auto\"}\n",
        "from IPython.display import display, HTML\n",
        "import base64\n",
        "from html import escape\n",
        "\n",
        "# see: https://stackoverflow.com/a/53688522\n",
        "def image_to_data_url(filename):\n",
        "  ext = filename.split('.')[-1]\n",
        "  prefix = f'data:image/{ext};base64,'\n",
        "  with open(filename, 'rb') as f:\n",
        "    img = f.read()\n",
        "  return prefix + base64.b64encode(img).decode('utf-8')\n",
        "\n",
        "pae = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_pae.png\"))\n",
        "cov = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_coverage.png\"))\n",
        "plddt = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_plddt.png\"))\n",
        "display(HTML(f\"\"\"\n",
        "<style>\n",
        "  img {{\n",
        "    float:left;\n",
        "  }}\n",
        "  .full {{\n",
        "    max-width:100%;\n",
        "  }}\n",
        "  .half {{\n",
        "    max-width:50%;\n",
        "  }}\n",
        "  @media (max-width:640px) {{\n",
        "    .half {{\n",
        "      max-width:100%;\n",
        "    }}\n",
        "  }}\n",
        "</style>\n",
        "<div style=\"max-width:90%; padding:2em;\">\n",
        "  <h1>Plots for {escape(jobname)}</h1>\n",
        "  <img src=\"{pae}\" class=\"full\" />\n",
        "  <img src=\"{cov}\" class=\"half\" />\n",
        "  <img src=\"{plddt}\" class=\"half\" />\n",
        "</div>\n",
        "\"\"\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "33g5IIegij5R"
      },
      "outputs": [],
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "if msa_mode == \"custom\":\n",
        "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "files.download(f\"{jobname}.result.zip\")\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#4. Instrucciones e información adicional\n",
        "**Quick start**\n",
        "1. Pega la secuencia de tu(s) proteína(s) en el campo de entrada.\n",
        "2. Pulsa \"Runtime\" -> \"Run all\".\n",
        "3. El pipeline consta de 5 pasos. Los pasos que se están ejecutando actualmente se indican mediante un círculo con una señal de alto al lado.\n",
        "\n",
        "**Contenido del fichero zip de resultados**\n",
        "\n",
        "1. Estructuras en formato PDB ordenadas por el valor medio de pLDDT y, en el caso de complejos, por el valor de pTMscore. (norelajada y relajada si la opción `use_amber` está habilitada).\n",
        "2. Representación de la calidad del modelo.\n",
        "3. Representación de la covertura del MSA (Multiple Sequence Alignement).\n",
        "4. Fichero log de los parametros.\n",
        "5. MSA de entrada en formato A3M.\n",
        "6. Un `predicted_aligned_error_v1.json` utilizando [AlphaFold-DB's format](https://alphafold.ebi.ac.uk/faq#faq-7) y un `scores.json` para cada modelo que contiene una matriz (lista de listas) para PAE, una lista con el pLDDT promedio y el pTMscore.\n",
        "7. Un fichero BibTeX con las citas para todas las herramientas y bases de datos usadas.\n",
        "\n",
        "Al final del trabajo, aparecerá un cuadro de descarga con un archivo `jobname.result.zip`. Además, si se seleccionó la opción `save_to_google_drive`, `jobname.result.zip` se cargará en tu Google Drive.\n",
        "\n",
        "\n",
        "**Generación de MSA para complejos**\n",
        "\n",
        "Para la predicción de complejos usamos MSA emparejados y no emparejados. El MSA no apareado se genera de la misma manera que para la predicción de estructuras de proteínas mediante la búsqueda de UniRef100 y las secuencias ambientales con tres iteraciones cada una.\n",
        "\n",
        "El MSA emparejado se genera buscando en la base de datos UniRef100 y emparejando los mejores resultados que comparten el mismo identificador taxonómico NCBI (= especie o subespecie). Solo emparejamos secuencias si todas las secuencias de consulta están presentes para el respectivo identificador  taxonómico.\n",
        "\n",
        "**Usar un MSA personalizado como entrada**\n",
        "\n",
        "Para predecir la estructura con un MSA personalizado (formato A3M): (1) Cambie msa_mode: a \"personalizado\", (2) Espere a que aparezca un cuadro de carga al final del cuadro \"Proteína de entrada...\". Sube tu A3M. La primera entrada fasta del A3M debe ser la secuencia de consulta sin espacios.\n",
        "\n",
        "Podemos utilizar el servidor [HHblits Toolkit server](https://toolkit.tuebingen.mpg.de/tools/hhblits) como una alternativa para la generación de MSA. Después de enviar tu consulta, haz clic en \"Consultar plantilla MSA\" -> \"Descargar A3M completo\". Descarga el archivo A3M y cárgalo en este cuaderno.\n",
        "\n",
        "**Comparación con AlphaFold2 y Alphafold2 completa de Colab**\n",
        "\n",
        "Este cuaderno reemplaza la detección de homología y el emparejamiento MSA de AlphaFold2 con MMseqs2. Para una comparación con [AlphaFold2 Colab](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb) y el sistema completo de [AlphaFold2](https://github.com/deepmind/alphafold) leer el artículo [preprint](https://www.biorxiv.org/content/10.1101/2021.08.15.456425v1).\n",
        "\n",
        "**Solución de problemas**\n",
        "* Verifique que el tipo de `Runtime` esté configurado en GPU en `Runtime` -> `Change Runtime type`.\n",
        "* Intente reiniciar la sesión `Runtime`-> `Factory reset runtime`.\n",
        "* Verifica la secuencia de entrada.\n",
        "\n",
        "**Problemas conocidos**\n",
        "* Google Colab asigna diferentes tipos de GPU con diferentes cantidades de memoria. Algunos podrían no tener suficiente memoria para predecir la estructura de una secuencia larga.\n",
        "* Su navegador puede bloquear la ventana emergente para descargar el archivo de resultados. En su lugar, puedes elegir la opción `save_to_google_drive` para subir a Google Drive ell archivo o descargarlo manualmente con el siguiente procedimiento: haga clic en el ícono de la carpeta pequeña a la izquierda, navegue hasta el archivo:`jobname.result.zip`, click derecho y selecciona   \\\"Download\\\" (ver [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "**Limitaciones**\n",
        "* Recursos informáticos: nuestra API MMseqs2 puede gestionar entre 20 000 y 50 000 solicitudes al día.\n",
        "* MSA: MMseqs2 es muy preciso y sensible, pero puede encontrar menos coincidencias en comparación con HHblits/HMMer buscado en BFD o Mgnify.\n",
        "* Recomendamos usar adicionalmente la [pipeline AlphaFold2](https://github.com/deepmind/alphafold) completa.\n",
        "\n",
        "\n",
        "**Descripción de las representaciones gráficas**\n",
        "* **Número de secuencias por posición**: queremos ver al menos 30 secuencias por posición, para obtener el mejor rendimiento, idealmente 100 secuencias.\n",
        "* **IDDT previsto por posición**: confianza del modelo (sobre 100) en cada posición. Cuanto más alto, mejor.\n",
        "* **Error de alineación previsto**: para los homooligómeros, esta podría ser una métrica útil para evaluar la confianza del modelo en la interfaz. Cuanto más bajo, mejor.\n",
        "\n",
        "**Bugs**\n",
        "- Si encuentra algún error, informe el problema a https://github.com/sokrypton/ColabFold/issues\n",
        "\n",
        "\n",
        "**Licencia**\n",
        "\n",
        "El código fuente de ColabFold está bajo licencia[MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Además, este cuaderno utiliza el código fuente de AlphaFold2 y sus parámetros bajo licencia[Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) y [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectivamente. Para leer más sobre la licencia de AlphaFold [here](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Acknowledgments**\n",
        "- Agradecemos al equipo de AlphaFold por desarrollar un modelo excelente y abrir el software.\n",
        "\n",
        "- [Söding Lab](https://www.mpibpc.mpg.de/soeding) por proporcionar los recursos computacionales para el servidor MMseqs2\n",
        "\n",
        "- Richard Evans por ayudar a comparar el soporte de multímero Alphafold de Colab Gold\n",
        "\n",
        "- [David Koes](https://github.com/dkoes) por su asombrosa aplicación [py3Dmol](https://3dmol.csb.pitt.edu/), ¡sin los cuales estos cuadernos serían bastante aburridos!\n",
        "\n",
        "- Do-Yoon Kim por crear el logo de ColabFold.\n",
        "\n",
        "- Un colab por Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) y Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}